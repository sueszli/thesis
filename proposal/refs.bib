@article{jabary2024seeing,
  title={Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs},
  author={Jabary, Yahya and Plesner, Andreas and Kuzhagaliyev, Turlan and Wattenhofer, Roger},
  journal={arXiv preprint arXiv:2409.05558},
  year={2024}
}

@article{sheikh2022novel,
  title={A Novel Animated CAPTCHA Technique based on Persistence of Vision},
  author={Sheikh, Shafiya Afzal and Banday, M Tariq},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={13},
  number={2},
  year={2022},
  publisher={Science and Information (SAI) Organization Limited}
}

@misc{9121132,
  abstract     = {{This thesis seeks to examine the suitability and robustness of transfer learning models in creating an efficient reCAPTCHA v2 classifier, and further evaluates their performance against various adversarial attacks. Three models - DenseNet201, EfficientNetV2, and InceptionV3 - were trained and assessed, highlighting the applicability of transfer learning techniques in the classification of reCAPTCHA v2 challenges. Despite variation in performance metrics, all models achieved satisfactory results, with DenseNet201 outperforming others in validation and test accuracy, and InceptionV3 demonstrating shortest training time.

The paper additionally showed varying levels of robustness for several different adversarial attacks among the models, with EfficientNetV2 proving to be the most resilient. This variability, despite identical top layers, points to the underlying base architecture as a significant determinant of a model's robustness against adversarial attacks. Consequently, the study supports a comprehensive evaluation for model selection, considering not only the performance of metrics but also the underlying model’s architectural properties that may affect its robustness.

Finally, this work indicates the potential of transfer learning models for image-based CAPTCHA challenge classification and stresses the need for further research focusing on enhancing the adversarial robustness of these models. The findings of this study contribute to the expanding body of research on transfer learning, showcasing its potential applications in the domain of image-based CAPTCHA systems.}},
  author       = {{Björklund, Arvid and Uogele, Marius}},
  language     = {{eng}},
  note         = {{Student Paper}},
  title        = {{Classifying Google reCAPTCHA v2 - A study using transfer learning models and evaluating their robustness against adversarial perturbations}},
  year         = {{2023}},
}

@article{hossen2019bots,
  title={Bots Work Better than Human Beings: An Online System to Break Google’s Image-based reCaptcha v2},
  author={Hossen, I and Tu, Yazhou and Rabby, F and Islam, Md Nazmul and Cao, Hui and Hei, Xiali},
  year={2019}
}

@inproceedings{sukhani2021automating,
  title={Automating the bypass of image-based CAPTCHA and assessing security},
  author={Sukhani, Krish and Sawant, Sahil and Maniar, Sarthak and Pawar, Renuka},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  pages={01--08},
  year={2021},
  organization={IEEE}
}

@inproceedings{hossen2020object,
  title={An Object Detection based Solver for $\{$Google’s$\}$ Image $\{$reCAPTCHA$\}$ v2},
  author={Hossen, Md Imran and Tu, Yazhou and Rabby, Md Fazle and Islam, Md Nazmul and Cao, Hui and Hei, Xiali},
  booktitle={23rd international symposium on research in attacks, intrusions and defenses (RAID 2020)},
  pages={269--284},
  year={2020}
}

@inproceedings{plesner2024breaking,
  title={Breaking reCAPTCHAv2},
  author={Plesner, Andreas and Vontobel, Tobias and Wattenhofer, Roger},
  booktitle={48th IEEE International Conference on Computers, Software, and Applications (COMPSAC 2024)},
  year={2024},
  organization={IEEE}
}

@article{shamir2021dimpled,
  title={The dimpled manifold model of adversarial examples in machine learning},
  author={Shamir, Adi and Melamed, Odelia and BenShmuel, Oriel},
  journal={arXiv preprint arXiv:2106.10151},
  year={2021}
}

@article{cubuk2017intriguing,
  title={Intriguing properties of adversarial examples},
  author={Cubuk, Ekin D and Zoph, Barret and Schoenholz, Samuel S and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.02846},
  year={2017}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{papernot2016limitations,
  title={The limitations of deep learning in adversarial settings},
  author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
  booktitle={2016 IEEE European symposium on security and privacy (EuroS\&P)},
  pages={372--387},
  year={2016},
  organization={IEEE}
}

@article{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{papernot2016distillation,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={2016 IEEE symposium on security and privacy (SP)},
  pages={582--597},
  year={2016},
  organization={IEEE}
}

@article{elsayed2018adversarial,
  title={Adversarial examples that fool both computer vision and time-limited humans},
  author={Elsayed, Gamaleldin and Shankar, Shreya and Cheung, Brian and Papernot, Nicolas and Kurakin, Alexey and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{hitaj2020capture,
  title={Capture the bot: Using adversarial examples to improve captcha robustness to bot attacks},
  author={Hitaj, Dorjan and Hitaj, Briland and Jajodia, Sushil and Mancini, Luigi V},
  journal={IEEE Intelligent Systems},
  volume={36},
  number={5},
  pages={104--112},
  year={2020},
  publisher={IEEE}
}

@misc{kilcher2021dimpled,
  author = {Yannic Kilcher},
  title = {{The Dimpled Manifold Model of Adversarial Examples in Machine Learning (Research Paper Explained)}},
  howpublished = "\url{https://www.youtube.com/watch?v=k_hUdZJNzkU/}",
  year = {2021}, 
  note = "[Online; accessed 17-July-2024]"
}

@misc{solverplugin,
  author = {2captcha},
  title = {{2captcha Chrome Plugin}},
  howpublished = "\url{https://chromewebstore.google.com/detail/captcha-solver-auto-recog/ifibfemgeogfhoebkmokieepdoobkbpo?hl=en}",
  year = {2021}, 
  note = "[Online; accessed 17-July-2024]"
}

@misc{kilcher2021dimpledcode,
  author = {Yannic Kilcher},
  title = {{dimple test}},
  howpublished = "\url{https://gist.github.com/yk/de8d987c4eb6a39b6d9c08f0744b1f64/}",
  year = {2021}, 
  note = "[Online; accessed 17-July-2024]"
}

@misc{captchashare,
  author = {6sense},
  title = {{Google Captcha Market Share}},
  howpublished = "\url{https://6sense.com/tech/captcha/recaptcha-market-share#:~:text=What%20is%20reCAPTCHA%20market%20share,of%2099.93%25%20in%20captcha%20market}",
  year = {2023},
  note = "[Online; accessed 17-July-2024]"
}

@misc{karner2023dimpled,
  author = {Lukas Karner},
  title = {{The Dimpled Manifold Revisited}},
  howpublished = "\url{https://github.com/LukasKarner/dimpled-manifolds/}",
  year = {2023}, 
  note = "[Online; accessed 17-July-2024]"
}

@inproceedings{elliott2021explaining,
  title={Explaining classifiers using adversarial perturbations on the perceptual ball},
  author={Elliott, Andrew and Law, Stephen and Russell, Chris},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10693--10702},
  year={2021}
}

@inproceedings{lu2024unsegment,
  title={Unsegment Anything by Simulating Deformation},
  author={Lu, Jiahao and Yang, Xingyi and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24294--24304},
  year={2024}
}

@inproceedings{im2022adversarial,
  title={Adversarial attack and defense of yolo detectors in autonomous driving scenarios},
  author={Im Choi, Jung and Tian, Qing},
  booktitle={2022 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1011--1017},
  year={2022},
  organization={IEEE}
}

@inproceedings{demontis2019adversarial,
  title={Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks},
  author={Demontis, Ambra and Melis, Marco and Pintor, Maura and Jagielski, Matthew and Biggio, Battista and Oprea, Alina and Nita-Rotaru, Cristina and Roli, Fabio},
  booktitle={28th USENIX security symposium (USENIX security 19)},
  pages={321--338},
  year={2019}
}
